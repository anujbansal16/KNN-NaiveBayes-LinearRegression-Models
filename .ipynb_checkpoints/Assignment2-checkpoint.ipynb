{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(trainFile,seperator=\",\"):\n",
    "    try:\n",
    "        data=pd.read_csv(trainFile, sep=seperator, header=None)\n",
    "        return data.values\n",
    "    except:\n",
    "        print(\"Error reading training data file\")\n",
    "# data1=readFile(\"Robot1\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(dataset,testdataset,targetIndex):\n",
    "    n=len(testdataset)\n",
    "    dist=0\n",
    "    for i in range(n):\n",
    "        if i==targetIndex:continue\n",
    "        temp=dataset[i]-testdataset[i];\n",
    "        dist+=temp*temp\n",
    "    return math.sqrt(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTrainTest(data,percent):\n",
    "    total=len(data)\n",
    "    trainTotal=int(total*percent*0.01)\n",
    "    testTotal=total-trainTotal\n",
    "    return (data[0:trainTotal],data[trainTotal:total])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNNAlgo(train,testRecord,k,targetIndex):\n",
    "    dists={}\n",
    "    for trainRecord in train:\n",
    "        dist=euclidean(trainRecord,testRecord,targetIndex)\n",
    "        dists[(str(trainRecord),trainRecord[targetIndex],dist)]=dist\n",
    "    sortedDict= sorted(dists.items(), key=operator.itemgetter(1))\n",
    "    labelDict={}\n",
    "    for i in range(k):\n",
    "#         print(sortedDict[i])\n",
    "        if sortedDict[i][0][1] in labelDict.keys():\n",
    "            labelDict[sortedDict[i][0][1]]+=1\n",
    "#             labelDict[sortedDict[i][0][1]][\"count\"]+=1\n",
    "#             if sortedDict[i][0][2]<labelDict[sortedDict[i][0][1]][\"min\"]:\n",
    "#                 labelDict[sortedDict[i][0][1]][\"min\"]=sortedDict[i][0][2]\n",
    "        else:\n",
    "            labelDict[sortedDict[i][0][1]]=1\n",
    "#             labelDict[sortedDict[i][0][1]]={}\n",
    "#             labelDict[sortedDict[i][0][1]][\"count\"]=1\n",
    "#             labelDict[sortedDict[i][0][1]][\"min\"]=sortedDict[i][0][2]\n",
    "#     print(labelDict)\n",
    "#     mn=-1\n",
    "#     count=0\n",
    "#     clas=None\n",
    "#     for label in labelDict:\n",
    "#         record=labelDict[label]\n",
    "#         if record[\"count\"]>count:\n",
    "#             count=record[\"count\"]\n",
    "#             clas=label\n",
    "#             mn=record[\"min\"]\n",
    "#         elif record[\"count\"]==count:\n",
    "#             if record[\"min\"]<mn:\n",
    "#                 mn=record[\"mn\"]\n",
    "#                 clas=label\n",
    "#     print(mn,count,clas,testRecord[0])\n",
    "#     return clas\n",
    "    return max(labelDict.items(),key=operator.itemgetter(1))[0]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(train,test,k):\n",
    "    count=0\n",
    "    for testRecord in test:\n",
    "        if testRecord[0]==KNNAlgo(train,testRecord,k,0):\n",
    "            count+=1\n",
    "    print(\"Accuracy \", count*100/len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainPredict1(trainFile1,trainFile2,percent,k,targetIndex):\n",
    "    data1=readFile(trainFile1,\" \")\n",
    "    data2=readFile(trainFile2,\" \")\n",
    "    data=np.concatenate((data1,data2))\n",
    "    data=np.delete(data, targetIndex, 1)\n",
    "    data=np.delete(data, 7, 1)\n",
    "    print(len(data))\n",
    "    train,test=splitTrainTest(data,percent)\n",
    "    print(len(train))\n",
    "    print(len(test))\n",
    "    predict(train,test,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainPredict2(trainFile,percent,k,targetIndex):\n",
    "    data=readFile(trainFile)\n",
    "    data=np.delete(data, targetIndex, 1)\n",
    "    print(len(data))\n",
    "    train,test=splitTrainTest(data,percent)\n",
    "    print(len(train))\n",
    "    print(len(test))\n",
    "    predict(train,test,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246\n",
      "196\n",
      "50\n",
      "Accuracy  54.0\n"
     ]
    }
   ],
   "source": [
    "trainPredict1(\"Robot1\",\"Robot2\",80,27,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "67\n",
      "68\n",
      "Accuracy  7.352941176470588\n"
     ]
    }
   ],
   "source": [
    "trainPredict2(\"Iris.csv\",50,17,4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
